{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN\n",
    "- 복잡한 데이터 학습위해 히든레이어 늘려보기\n",
    "- 오버피팅의 위험이 있지만 이를 위한 방법들 존재\n",
    "\n",
    "#### Vanishing gradient\n",
    "- activation function에 따라 vanishing gradient가 발생할 수 있음\n",
    "- 여러 레이어로 구성된 DNN에서 각 레이어 사이에 activation function이 반복적으로 들어있기 때문에\n",
    "    - 오차역전파를 계산할 때 경사도가 누적..\n",
    "- 특히 sigmoid는 입력을 특정 범위로 줄여버리기 때문에\n",
    "    - 이처럼 입력을 특정 범위로 줄이는 activation function들은 \n",
    "    - 입력이 크면 경사도도 매우 작아져(끝부분에 기울기 거의0) 기울기 소실 유발가능성\n",
    "    - 0근처의 작은 입력에 대해서만 기울기 온전함\n",
    "- ReLu가 해결책이 될 수. 0보다 큰 구간에선 직선 함수라서 값이 커져도 기울기 구할 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nin = 784\n",
    "Nh_l = [100 ,50]\n",
    "number_of_class = 10\n",
    "Nout = number_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "class DNN(models.Sequential):\n",
    "    def __init__(self, Nin, Nh_l, Nout):\n",
    "        super().__init__() # 연쇄 방식으로 구성할 땐, 부모의 초기화를 먼저해서 모델의 시작을 알려야함\n",
    "        # 연쇄 방식으로 할 때는, 특정 계층의 입력 노드 수를 자동으로 설정해줌 (맨 첫 레이어는 제외)\n",
    "        self.add(layers.Dense(Nh_l[0], activation='relu', input_shape=(Nin,), name='Hidden-1'))\n",
    "        self.add(layers.Dropout(0.2))\n",
    "        self.add(layers.Dense(Nh_l[1], activation='relu', name='Hidden-2'))\n",
    "        self.add(layers.Dropout(0.2))\n",
    "        self.add(layers.Dense(Nout, activation='softmax'))\n",
    "        self.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import datasets\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "L, W, H = X_train.shape\n",
    "X_train = X_train.reshape(-1, W * H)\n",
    "X_test = X_test.reshape(-1, W * H)\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.5185 - acc: 0.8436 - val_loss: 0.1961 - val_acc: 0.9433\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.2372 - acc: 0.9301 - val_loss: 0.1440 - val_acc: 0.9575\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1836 - acc: 0.9453 - val_loss: 0.1255 - val_acc: 0.9618\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.1535 - acc: 0.9536 - val_loss: 0.1111 - val_acc: 0.9667\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.1310 - acc: 0.9613 - val_loss: 0.1041 - val_acc: 0.9703\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.1189 - acc: 0.9641 - val_loss: 0.1009 - val_acc: 0.9718\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.1055 - acc: 0.9675 - val_loss: 0.0963 - val_acc: 0.9715\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 2s 45us/step - loss: 0.0981 - acc: 0.9698 - val_loss: 0.0917 - val_acc: 0.9733\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 2s 41us/step - loss: 0.0897 - acc: 0.9722 - val_loss: 0.0920 - val_acc: 0.9734\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 2s 43us/step - loss: 0.0822 - acc: 0.9748 - val_loss: 0.0901 - val_acc: 0.9749\n",
      "10000/10000 [==============================] - 0s 16us/step\n",
      "Test Loss and Accuracy ->  [0.07973407174620661, 0.9769000059366226]\n"
     ]
    }
   ],
   "source": [
    "model = DNN(Nin, Nh_l, Nout)\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=100, validation_split=0.2)\n",
    "performance_test = model.evaluate(X_test, y_test, batch_size=100)\n",
    "print('Test Loss and Accuracy -> ', performance_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
